{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"","text":"<p>Hello  !</p> <p>I'm  Jatin Kumar.  Currently working as Software Engineer @StepSecurity Inc.</p> <p>At StepSecurity, I spent most of my time creating, debugging &amp; improving <code>Agents</code>. They are EDR like softwares that are purpose built for securing CI/CD pipeline runners from <code>SolarWinds and tj-actions</code> like software-supply-chain attacks. Harden-Runner is one of the widely used open-source variant specifically developed for <code>Github Actions.</code></p> <p>Off job, I spent time exploring new-things, reading or experimenting.</p> <p>Thanks !</p> <p>Reach out to me on Linkedin...</p> <p>Note</p> <p><code>Unnamed Memories</code> is a centralized repo of my notes, logs, experiences and more.</p>"},{"location":"achievements/","title":"Achievements","text":""},{"location":"achievements/#bug-hunting","title":"Bug Hunting","text":""},{"location":"achievements/#google-vrp","title":"Google VRP","text":"<p>Profile: https://bughunters.google.com/profile/1db4e6b5-400a-4250-8152-88c548e36f24</p> <p>Valid Public Reports</p> <ul> <li>https://bughunters.google.com/reports/vrp/jALhjoMUo</li> <li>https://bughunters.google.com/reports/vrp/VZcSaHcyp</li> </ul>"},{"location":"achievements/#ctfs","title":"CTFs","text":""},{"location":"achievements/#aws-proactive-security-spain-ctf-march-2024","title":"AWS Proactive Security Spain CTF, March 2024","text":"<ul> <li>Organizer: AWS Spain</li> <li>Position: 5th</li> </ul>"},{"location":"achievements/#aws-proactive-security-spain-ctf-nov-2022","title":"AWS Proactive Security Spain CTF, Nov 2022","text":"<ul> <li>Organizer: AWS Spain</li> <li>Position: 2nd</li> </ul>"},{"location":"achievements/#cyberkshetra21-2021","title":"CyberKshetra'21, 2021","text":"<ul> <li>Organizer: Deloitte</li> <li>Position: 3rd</li> </ul>"},{"location":"experiences/","title":"Experiences","text":""},{"location":"experiences/#software-engineer-full-time-stepsecurity-inc","title":"Software Engineer (Full-time) | StepSecurity Inc.","text":"<p> July-2023 to Present</p> <ul> <li> <p>Responsible for <code>R&amp;D</code> of eBPF-based solutions for <code>network, process and file visibility</code> and <code>policy-enforcement</code>.</p> </li> <li> <p>Designed, developed and maintaining a portable eBPF based module with following capabilities, </p> <ul> <li>traces every <code>outgoing network-packet</code></li> <li>traces every <code>dns-resolution</code></li> <li>can be configured to act as <code>policy-based firewall</code> such that it,<ul> <li><code>blocks dns-resolutions</code> not in allow-policy</li> <li><code>blocks ip-connections</code> not in allow-policy</li> </ul> </li> </ul> </li> <li> <p>Leading the <code>R&amp;D of eBPF based armour</code> to detect/protect agents from tampering attacks.</p> </li> <li> <p>Still contributing/maintaining Harden-Runner.</p> </li> </ul>"},{"location":"experiences/#software-developer-part-time-stepsecurity-inc","title":"Software Developer (Part-Time) | StepSecurity Inc.","text":"<p> April-2022 to June-2023</p> <ul> <li> <p>Responsible for porting runtime-security solution to ARC-based self-hosted runners.</p> </li> <li> <p>Implemented <code>eBPF-based</code> HTTPS traffic interception capability in agent.</p> </li> <li> <p>Automated implementation of security best\u2011practices in GitHub Actions workflow files. </p> </li> <li> <p>Continued maintenance work on runtime security agent for CI/CD runners.</p> </li> <li> <p>Automated the manual-static-analysis process to figure GITHUB_TOKEN permissions for third-party Github Actions.</p> </li> <li> <p>Started contributing to Harden-Runner.</p> </li> </ul>"},{"location":"experiences/#software-developer-intern-stepsecurity-inc","title":"Software Developer (Intern) | StepSecurity Inc.","text":"<p> January-2022 to March-2022</p> <ul> <li> <p>Performed source\u2011code\u2011analysis of <code>50+ OpenSource third-Party Github Actions</code> for determining their GITHUB_TOKEN permissions.</p> <ul> <li>Stored the analyzed-info in open-source knowledge-Database.</li> </ul> </li> <li> <p>Raised 15+ PRs in Github-Actions start-workflows to restrict permissions to least-privileges.</p> <ul> <li>Resulting in <code>secure-by-default</code> starter-workflow.</li> </ul> </li> <li> <p>Implemented unit-tests/bug-fixes in step-security agent.</p> </li> </ul>"},{"location":"oss/","title":"OpenSource Contrib.","text":""},{"location":"oss/#gojueecapture","title":"gojue/ecapture","text":"<ul> <li> <p>ISSUE-443: Investigated memory-leak occurring in creating perCPUBuffer for eBPF sensors</p> </li> <li> <p>PR-438: Reduced memory consumption in OPENSSL version detection logic by refactoring the existing logic to use fixed-buffer.</p> </li> <li> <p>PR-426: Implemented support for capturing HTTPS traffic from stripped Go binaries resulting in improved inspection of traffic.</p> </li> <li> <p>PR-418: Implemented support for decoding kernel-time received from eBPF event to user-time resulting in accurate event-timestamp.</p> </li> </ul>"},{"location":"oss/#ossfscorecard","title":"ossf/scorecard","text":"<ul> <li>PR-2278: Investigated and fixed a bug causing miscalculation of scores for private GitHub repositories.</li> </ul>"},{"location":"oss/#ossfpackage-analysis","title":"ossf/package-analysis","text":"<ul> <li>PR-978: Refactored static-analysis result struct to include SHA256 checksum of the target archive</li> </ul>"},{"location":"blog/","title":"Logs","text":""},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/","title":"eBPF: Connecting with Container Runtimes","text":""},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#objective","title":"Objective","text":"<ul> <li>to understand how connection with <code>Container Runtime (CR)</code> is being made using <code>Container Runtime Interface (CRI)</code> in different open-source eBPF-based projects.<ul> <li>to query <code>pod or container info</code> for context enrichment.</li> </ul> </li> </ul>  Featured in  <ul> <li>Cilium's bi-weekly eCHO News Episode #86</li> <li>Hacker News thread#44524430</li> </ul>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#reasoning","title":"Reasoning","text":"Note <p>Code snippets are take from open-source tetragon, tracee and crictl projects.</p> <p>Connection with CR is important for making the tool/product kubernetes-aware. As it provides rich information that could be of interest for different use-cases.</p> <p>Connection with CR involves following steps</p> <ul> <li>locate <code>unix-socket</code> file</li> <li>make a grpc connection using CRI API</li> <li>query the info</li> </ul>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#locate-unix-socket-file","title":"Locate <code>unix-socket</code> file","text":"Tip <p>Make sure to mount host <code>/var</code> or <code>/run</code> in container.</p> <p>Most of the times these are in a well-known location such as <code>/var/run</code> or <code>/run</code>. Checkout CR documentation for exact location.</p> <p>In projects that I explored, well-known paths are hardcoded for flexibility. </p> <p>During runtime, code iterate over these paths, tries to make a connection and returns the corresponding service, if it was success.</p>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tetragon","title":"Tetragon","text":"<p>Tetragon contains some hardcoded default sock-paths. [Source] <pre><code>    defaultEndpoints = []string{\n        \"unix:///run/containerd/containerd.sock\",\n        \"unix:///run/crio/crio.sock\",\n        \"unix:///var/run/cri-dockerd.sock\",\n    }\n</code></pre></p>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#crictl","title":"Crictl","text":"<p>Browse full source-code</p> <pre><code>var defaultRuntimeEndpoints = []string{\"unix:///run/containerd/containerd.sock\", \"unix:///run/crio/crio.sock\", \"unix:///var/run/cri-dockerd.sock\"}\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tracee","title":"Tracee","text":"<p>Browse full source-code</p> <pre><code>func Autodiscover(onRegisterFail func(err error, runtime RuntimeId, socket string)) Sockets {\n    register := func(sockets *Sockets, runtime RuntimeId, socket string) {\n        err := sockets.Register(runtime, socket)\n        if err != nil {\n            onRegisterFail(err, runtime, socket)\n        }\n    }\n    sockets := Sockets{}\n    const (\n        defaultContainerd = \"/var/run/containerd/containerd.sock\"\n        defaultDocker     = \"/var/run/docker.sock\"\n        defaultCrio       = \"/var/run/crio/crio.sock\"\n        defaultPodman     = \"/var/run/podman/podman.sock\"\n    )\n\n    register(&amp;sockets, Containerd, defaultContainerd)\n    register(&amp;sockets, Docker, defaultDocker)\n    register(&amp;sockets, Crio, defaultCrio)\n    register(&amp;sockets, Podman, defaultPodman)\n\n    return sockets\n}\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#making-connection","title":"Making connection","text":""},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tetragon_1","title":"Tetragon","text":"<p>Browse full source-code <pre><code>// required modules\nimport (\n    \"google.golang.org/grpc\"\n    \"google.golang.org/grpc/credentials/insecure\"\n     criapi \"k8s.io/cri-api/pkg/apis/runtime/v1\"\n)\n\nfunc newClientTry(ctx context.Context, endpoint string) (criapi.RuntimeServiceClient, error) {\n\n    u, err := url.Parse(endpoint)\n    if err != nil {\n        return nil, err\n    }\n    if u.Scheme != \"unix\" {\n        return nil, errNotUnix\n    }\n\n    conn, err := grpc.NewClient(endpoint,\n        grpc.WithTransportCredentials(insecure.NewCredentials()),\n    )\n    if err != nil {\n        return nil, err\n    }\n\n    rtcli := criapi.NewRuntimeServiceClient(conn)\n    if _, err := rtcli.Version(ctx, &amp;criapi.VersionRequest{}); err != nil {\n        return nil, fmt.Errorf(\"validate CRI v1 runtime API for endpoint %q: %w\", endpoint, err)\n    }\n\n    return rtcli, nil\n}\n</code></pre></p>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#crictl_1","title":"Crictl","text":"<p>Browse full source-code</p> <pre><code>// required modules\nimport(\n  ...\n  internalapi \"k8s.io/cri-api/pkg/apis\"\n  remote \"k8s.io/cri-client/pkg\"\n  ...\n)\n\n...\nfor _, endPoint := range defaultRuntimeEndpoints {\n    logrus.Debugf(\"Connect using endpoint %q with %q timeout\", endPoint, t)\n\n    res, err = remote.NewRemoteRuntimeService(endPoint, t, tp, &amp;logger)\n    if err != nil {\n        logrus.Error(err)\n\n        continue\n    }\n\n    logrus.Debugf(\"Connected successfully using endpoint: %s\", endPoint)\n\n    break\n}\n...\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tracee_1","title":"Tracee","text":"<p>Browse full source-code</p> <pre><code>func ContainerdEnricher(socket string) (ContainerEnricher, error) {\n    enricher := containerdEnricher{}\n\n    // avoid duplicate unix:// prefix\n    unixSocket := \"unix://\" + strings.TrimPrefix(socket, \"unix://\")\n\n    client, err := containerd.New(socket)\n    if err != nil {\n        return nil, errfmt.WrapError(err)\n    }\n\n    conn, err := grpc.NewClient(unixSocket, grpc.WithTransportCredentials(insecure.NewCredentials()))\n    if err != nil {\n        if errC := client.Close(); errC != nil {\n            logger.Errorw(\"Closing containerd connection\", \"error\", errC)\n        }\n        return nil, errfmt.WrapError(err)\n    }\n\n    enricher.images_cri = cri.NewImageServiceClient(conn)\n    enricher.containers = client.ContainerService()\n    enricher.namespaces = client.NamespaceService()\n    enricher.images = client.ImageService()\n\n    return &amp;enricher, nil\n}\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#query-the-info","title":"Query the info","text":""},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tetragon_2","title":"Tetragon","text":"<p>Querying cgroup-path of a container. [Source]</p> <pre><code>func CgroupPath(ctx context.Context, cli criapi.RuntimeServiceClient, containerID string) (string, error) {\n\n  // creating a request \n    req := criapi.ContainerStatusRequest{\n        ContainerId: containerID,\n        Verbose:     true,\n    }\n\n  // making grpc call\n    res, err := cli.ContainerStatus(ctx, &amp;req)\n    if err != nil {\n        return \"\", err\n    }\n\n  // taking the info\n    info := res.GetInfo()\n    if info == nil {\n        return \"\", errors.New(\"no container info\")\n    }\n\n  // extracting the relevant info\n\n    var path, json string\n    if infoJson, ok := info[\"info\"]; ok {\n        json = infoJson\n        path = \"runtimeSpec.linux.cgroupsPath\"\n    } else {\n        return \"\", errors.New(\"could not find info\")\n    }\n\n    ret := gjson.Get(json, path).String()\n    if ret == \"\" {\n        return \"\", errors.New(\"failed to find cgroupsPath in json\")\n    }\n\n    return ParseCgroupsPath(ret)\n}\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#tracee_2","title":"Tracee","text":"<p>Browse full source-code</p> tracee-snippet.go<pre><code>func (e *containerdEnricher) Get(ctx context.Context, containerId string) (EnrichResult, error) {\n    res := EnrichResult{}\n    nsList, err := e.namespaces.List(ctx)\n    if err != nil {\n        return res, errfmt.Errorf(\"failed to fetch namespaces %s\", err.Error())\n    }\n    for _, namespace := range nsList {\n        // always query with namespace applied\n        nsCtx := namespaces.WithNamespace(ctx, namespace)\n\n        // if containers is not in current namespace, search the next one\n        container, err := e.containers.Get(nsCtx, containerId)\n        if err != nil {\n            continue\n        }\n\n    ....\n\n        // if in k8s we can extract pod info from labels\n        if container.Labels != nil {\n            labels := container.Labels\n            res.PodName = labels[PodNameLabel]\n            res.Namespace = labels[PodNamespaceLabel]\n            res.UID = labels[PodUIDLabel]\n            res.Sandbox = e.isSandbox(labels)\n\n            // containerd containers normally have no names unless set from k8s\n            res.ContName = labels[ContainerNameLabel]\n        }\n        res.Image = imageName\n        res.ImageDigest = imageDigest\n\n        return res, nil\n    }\n\n    return res, errfmt.Errorf(\"failed to find container %s in any namespace\", containerId)\n}\n</code></pre>"},{"location":"blog/2025/06/29/ebpf-connecting-with-container-runtimes/#refer","title":"Refer","text":"<ul> <li>https://github.com/cilium/tetragon/blob/main/pkg/cri/cri.go</li> <li>https://github.com/cilium/tetragon/tree/main/pkg/cri</li> <li>https://github.com/kubernetes-sigs/cri-tools/blob/0cf370b13928d79146916fd9accbbc69f64a92b5/cmd/crictl/main.go#L73</li> <li>https://github.com/aquasecurity/tracee/tree/main/pkg/containers/runtime</li> </ul>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/","title":"eBPF: Handling events in Userspace","text":""},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#objective","title":"Objective","text":"<ul> <li>to understand how eBPF-events are being handled in userspace in various open-source projects<ul> <li>to learn their approach for handling massive amount of events</li> </ul> </li> </ul>  Featured in  <ul> <li>Cilium's bi-weekly eCHO News Episode #87</li> </ul>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#reasoning","title":"Reasoning","text":"Note <p>Snippets are take from  cilium/tetragon and aquasecurity/tracee projects.</p> <p>Once eBPF-events are written by the kernel-space hook in <code>ringBuffer or perfBuffer</code>, they become available for consumption from user-space.</p> <p>Following steps are usually performed in user-space code;</p> <ol> <li>Preparation of ringBuffer / perfBuffer reader</li> <li>Reading of records from buffer</li> <li>Processing of raw-samples</li> </ol>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#tetragon","title":"Tetragon","text":""},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#preparation","title":"Preparation","text":"<p>PerfEvent reader is prepared from pinned perf-map. [Source]</p> snippet.go<pre><code>...\n    pinOpts := ebpf.LoadPinOptions{}\n    perfMap, err := ebpf.LoadPinnedMap(k.PerfConfig.MapName, &amp;pinOpts)\n    if err != nil {\n        return fmt.Errorf(\"opening pinned map '%s' failed: %w\", k.PerfConfig.MapName, err)\n    }\n    defer perfMap.Close()\n\n    rbSize := k.getRBSize(int(perfMap.MaxEntries()))\n    perfReader, err := perf.NewReader(perfMap, rbSize)\n\n...\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#reading","title":"Reading","text":"<p>A goroutine is launched;</p> <ul> <li>to read records from perfReader that adds them to <code>eventsQueue</code> (a buffered-channel). </li> </ul> <p>[Source]</p> snippet2.go<pre><code>...\n\n    // We spawn go routine to read and process perf events,\n    // connected with main app through eventsQueue channel.\n    eventsQueue := make(chan *perf.Record, k.getRBQueueSize())\n\n\n    // Listeners are ready and about to start reading from perf reader, tell\n    // user everything is ready.\n    k.log.Info(\"Listening for events...\")\n\n\n    // Start reading records from the perf array. Reads until the reader is closed.\n    var wg sync.WaitGroup\n    wg.Add(1)\n    defer wg.Wait()\n    go func() {\n            defer wg.Done()\n            for stopCtx.Err() == nil {\n                    record, err := perfReader.Read()\n                    if err != nil {\n                            // NOTE(JM and Djalal): count and log errors while excluding the stopping context\n                            if stopCtx.Err() == nil {\n                                    RingbufErrors.Inc()\n                                    errorCnt := getCounterValue(RingbufErrors)\n                                    k.log.Warn(\"Reading bpf events failed\", \"errors\", errorCnt, logfields.Error, err)\n                            }\n                    } else {\n                            if len(record.RawSample) &gt; 0 {\n                                    select {\n                                    case eventsQueue &lt;- &amp;record:\n                                    default:\n                                            // eventsQueue channel is full, drop the event\n                                            queueLost.Inc()\n                                    }\n                                    RingbufReceived.Inc()\n                            }\n\n\n                            if record.LostSamples &gt; 0 {\n                                    RingbufLost.Add(float64(record.LostSamples))\n                            }\n                    }\n            }\n    }()\n\n...\n</code></pre> <p>Another goroutine is launched;</p> <ul> <li>for reading records from eventsQueue, where they are passed to <code>receiveEvent()</code> for processing</li> </ul> <p>[Source]</p> snippet3.go<pre><code>...\n\n  // Start processing records from perf.\n  wg.Add(1)\n  go func() {\n          defer wg.Done()\n          for {\n                  select {\n                  case event := &lt;-eventsQueue:\n                          k.receiveEvent(event.RawSample)\n                          queueReceived.Inc()\n                  case &lt;-stopCtx.Done():\n                          k.log.Info(\"Listening for events completed.\", logfields.Error, stopCtx.Err())\n                          k.log.Debug(fmt.Sprintf(\"Unprocessed events in RB queue: %d\", len(eventsQueue)))\n                          return\n                  }\n          }\n  }()\n\n\n...\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#processing","title":"Processing","text":"<p>On calling <code>receiveEvent()</code></p> <ul> <li>it converts raw-bytes to <code>events</code> by passing data to <code>HandlePerfData()</code></li> <li>send events to various listeners</li> </ul> <p>[Source]</p> snippet4.go<pre><code>func (k *Observer) receiveEvent(data []byte) {\n        var timer time.Time\n        if option.Config.EnableMsgHandlingLatency {\n                timer = time.Now()\n        }\n\n\n        op, events, err := HandlePerfData(data)\n        opcodemetrics.OpTotalInc(ops.OpCode(op))\n        if err != nil {\n                errormetrics.HandlerErrorsInc(ops.OpCode(op), err.kind)\n                switch err.kind {\n                case errormetrics.HandlePerfUnknownOp:\n                        k.log.Debug(\"unknown opcode ignored\", \"opcode\", err.opcode)\n                default:\n                        k.log.Debug(\"error occurred in event handler\", \"opcode\", err.opcode, logfields.Error, err)\n                }\n        }\n        for _, event := range events {\n                k.observerListeners(event)\n        }\n        if option.Config.EnableMsgHandlingLatency {\n                opcodemetrics.LatencyStats.WithLabelValues(strconv.FormatUint(uint64(op), 10)).Observe(float64(time.Since(timer).Microseconds()))\n        }\n}\n</code></pre> <p>On calling <code>HandlePerfData()</code>;</p> <ul> <li>it tries to find event-specific handler using <code>first-byte</code></li> <li>calls the handler for parsing raw-bytes</li> </ul> <p>[Source]</p> snippet5.go<pre><code>func HandlePerfData(data []byte) (byte, []Event, *HandlePerfError) {\n        op := data[0]\n        r := bytes.NewReader(data)\n        // These ops handlers are registered by RegisterEventHandlerAtInit().\n        handler, ok := eventHandler[op]\n        if !ok {\n                return op, nil, &amp;HandlePerfError{\n                        kind:   errormetrics.HandlePerfUnknownOp,\n                        err:    fmt.Errorf(\"unknown op: %d\", op),\n                        opcode: op,\n                }\n        }\n\n\n        events, err := handler(r)\n        if err != nil {\n                return op, events, &amp;HandlePerfError{\n                        kind:   errormetrics.HandlePerfHandlerError,\n                        err:    fmt.Errorf(\"handler for op %d failed: %w\", op, err),\n                        opcode: op,\n                }\n        }\n        return op, events, nil\n}\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#tracee","title":"Tracee","text":"<p>As <code>Tracee</code> uses libbpfgo for loading eBPF objects, so there is a little difference in approach for <code>preparation and reading</code> of raw-data from perf/ring buffer. (extensive usage of go-channels)</p>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#preparation_1","title":"Preparation","text":"<p>[Source]</p> <p>PerfBuffer is initialized with <code>eventsChannel</code> a buffered-channel for receiving raw-event bytes.</p> snippet.go<pre><code>...\n    // Initialize perf buffers and needed channels\n\n    t.eventsChannel = make(chan []byte, 1000)\n    t.lostEvChannel = make(chan uint64)\n    if t.config.PerfBufferSize &lt; 1 {\n        return errfmt.Errorf(\"invalid perf buffer size: %d\", t.config.PerfBufferSize)\n    }\n    t.eventsPerfMap, err = t.bpfModule.InitPerfBuf(\n        \"events\",\n        t.eventsChannel,\n        t.lostEvChannel,\n        t.config.PerfBufferSize,\n    )\n    if err != nil {\n        return errfmt.Errorf(\"error initializing events perf map: %v\", err)\n    }\n...\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#reading-decoding","title":"Reading / Decoding","text":"<p>[Source]</p> <p>Then <code>handleEvents()</code> is launched in a separate goroutine for handling all perf-events:</p> <ul> <li>it further sends <code>eventsChannel</code> to decodeEvents() <ul> <li>that reads raw-events &amp; decodes them </li> <li>returns <code>eventsChan</code> for receiving decoded-events</li> </ul> </li> </ul> snippet2.go<pre><code>...\n// handleEvents is the main pipeline of tracee. It receives events from the perf buffer\n// and passes them through a series of stages, each stage is a goroutine that performs a\n// specific task on the event. The pipeline is started in a separate goroutine.\nfunc (t *Tracee) handleEvents(ctx context.Context, initialized chan&lt;- struct{}) {\n    logger.Debugw(\"Starting handleEvents goroutine\")\n    defer logger.Debugw(\"Stopped handleEvents goroutine\")\n\n    var errcList []&lt;-chan error\n\n    // Decode stage: events are read from the perf buffer and decoded into trace.Event type.\n\n    eventsChan, errc := t.decodeEvents(ctx, t.eventsChannel)\n    t.stats.Channels[\"decode\"] = eventsChan\n    errcList = append(errcList, errc)\n\n    // Cache stage: events go through a caching function.\n\n...\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#processing_1","title":"Processing","text":"<p>Events from <code>eventsChan</code> goes through several logical stages such as:</p> <ul> <li>container enrichment</li> <li>detection engine</li> </ul> <p>finally all events are handled by <code>sink stage</code> for printing/logging.</p> <p>[Source]</p> snippet3.go<pre><code>    // Process events stage: events go through a processing functions.\n\n    eventsChan, errc = t.processEvents(ctx, eventsChan)\n    t.stats.Channels[\"process\"] = eventsChan\n    errcList = append(errcList, errc)\n\n    // Enrichment stage: container events are enriched with additional runtime data.\n\n    if !t.config.NoContainersEnrich { // TODO: remove safe-guard soon.\n        eventsChan, errc = t.enrichContainerEvents(ctx, eventsChan)\n        t.stats.Channels[\"enrich\"] = eventsChan\n        errcList = append(errcList, errc)\n    }\n\n\n    // Derive events stage: events go through a derivation function.\n\n    eventsChan, errc = t.deriveEvents(ctx, eventsChan)\n    t.stats.Channels[\"derive\"] = eventsChan\n    errcList = append(errcList, errc)\n\n    // Engine events stage: events go through the signatures engine for detection.\n\n    if t.config.EngineConfig.Mode == engine.ModeSingleBinary {\n        eventsChan, errc = t.engineEvents(ctx, eventsChan)\n        t.stats.Channels[\"engine\"] = eventsChan\n        errcList = append(errcList, errc)\n    }\n\n    // Sink pipeline stage: events go through printers.\n    errc = t.sinkEvents(ctx, eventsChan)\n    t.stats.Channels[\"sink\"] = eventsChan\n    errcList = append(errcList, errc)\n</code></pre>"},{"location":"blog/2025/07/26/ebpf-handling-events-in-userspace/#references","title":"References","text":"<ul> <li>cilium/tetragon</li> <li>aquasecurity/tracee</li> <li>https://nakryiko.com/posts/bpf-ringbuf/</li> <li>https://docs.ebpf.io/linux/map-type/BPF_MAP_TYPE_RINGBUF/</li> <li>https://docs.ebpf.io/linux/map-type/BPF_MAP_TYPE_PERF_EVENT_ARRAY/</li> <li>https://www.kernel.org/doc/html/next/bpf/ringbuf.html</li> </ul>"},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/","title":"eBPF: Loading in different kernels","text":""},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#objective","title":"Objective","text":"<ul> <li>to learn loading compiled eBPF program in different kernels within <code>Github Actions</code><ul> <li>for testing its compatibility with kernel and observe if it loads correctly</li> </ul> </li> </ul>  Featured in <ul> <li>eBPFChirp \u2014The #1 eBPF newsletter on Substack</li> </ul>"},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#reasoning","title":"Reasoning","text":""},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#lvh","title":"LVH","text":"<p>For loading eBPF object in different kernels, we will be using little-vm-helper(LVH), an open-source cilium project for creating light-weight virtual machines.</p> <p>LVH has Github Action that can be used to launch a <code>little-vm</code> with a <code>custom linux-kernel image</code> inside Github Action Runner VM. </p>"},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#lvh-images","title":"LVH Images","text":"<p>Kernel images used by LVH are built using another open-source cilium project namely little-vm-helper-images.  These kernel-images are stored here.</p> <p>As of now 3 variants of images are available:</p> <ul> <li>base</li> <li>kind</li> <li>complexity-test</li> </ul> <p>These differ by:</p> <ul> <li> <p>userspace setup.</p> </li> <li> <p>packages: the kind of packages available inside them, e.g in some <code>dig</code> is not available.</p> </li> </ul>"},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#code","title":"Code","text":"<p>Note</p> <p>Try forking the ebpf-playground and triggering the workflows.</p> load.yml<pre><code>name: LVH Load\n\non:\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n\n  load-vm:\n    runs-on: ubuntu-latest\n    name: eBPF Load\n    strategy:\n      fail-fast: false\n      matrix:\n        kernel: # (1)!\n          - \"6.6-20250616.013250-amd64\" # (2)!\n          - \"5.15-20250616.013250-amd64\"\n          - \"5.10-20250610.043823-amd64\"\n\n    timeout-minutes: 10\n    steps:\n\n        # (3)!\n      - run: | \n          wget --quiet https://github.com/cilium/ebpf/raw/refs/heads/main/examples/cgroup_skb/bpf_bpfel.o  \n          ls -lah\n      # (4)!\n      - name: Provision LVH VMs\n        uses: cilium/little-vm-helper@v0.0.23\n        with:\n          test-name: load-test\n          image: \"kind\"\n          image-version: ${{ matrix.kernel }}\n          host-mount: .\n          install-dependencies: \"true\"\n          cmd: |\n            # print kernel version\n            echo \"Kernel Version: \"\n            uname -a\n\n            # goto where host is mounted\n            echo \"\"\n            cd /host\n            ls -lah\n\n            echo \"\"\n            sudo bpftool prog load ./bpf_bpfel.o /sys/fs/bpf/test &amp;&amp; echo \"Load Success\"\n</code></pre> <ol> <li>Visit here for getting kernel tags</li> <li>List of kernel images to test against.</li> <li>Downloading the eBPF object to load</li> <li> <p>Note</p> <ol> <li>Using LVH to provision virtual-machine with given kernel</li> <li>Mounting the <code>$PWD</code> inside VM at <code>/host</code></li> <li>Loading the program</li> </ol> </li> </ol>"},{"location":"blog/2025/06/21/ebpf-loading-in-different-kernels/#refer","title":"Refer","text":"<ul> <li>cilium/little-vm-helper</li> <li>https://github.com/cilium/little-vm-helper-images/blob/main/_data/images.json</li> <li> https://quay.io/repository/lvh-images/kind?tab=tags</li> <li>h0x0er/ebpf-playground</li> <li>cilium/ebpf</li> </ul>"},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/","title":"eBPF: Resetting tail-contexts","text":""},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#objective","title":"Objective","text":"<p>to understand ways of resetting/zeroing the perCPU contexts used in tail-calls</p>"},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#reasoning","title":"Reasoning","text":"<p>The <code>tail-context</code> must be zeroed before reusing it, to make sure values from previous executions are cleared. </p> <p>Following techniques can be used</p> <ol> <li> <p>Using <code>__builtin_memset()</code></p> <ul> <li>this fails to reset if size exceeds <code>1000-bytes</code></li> </ul> </li> <li> <p>By writing <code>null_bytes</code> in <code>tail-context</code></p> <ul> <li>requires additional <code>read-only</code> map containing null-bytes</li> <li>can reset context of any size</li> </ul> </li> <li> <p>Using <code>for-loop</code></p> <ul> <li>using this can sometimes lead to <code>instructions limit exceeded error</code></li> </ul> </li> </ol>"},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#snippets","title":"Snippets","text":""},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#memset","title":"memset","text":"memset.c<pre><code>// using __builtin_memset\nvoid reset_context1(struct tail_context* c){\n    __builtin_memset(c, 0, 2); // reset only 2 bytes\n}\n</code></pre>"},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#null_bytes","title":"null_bytes","text":"null_bytes.c<pre><code>u32 zero = 0;\nvoid reset_context2(struct tail_context* c){\n\n    __builtin_memset(c, 0, 2); // reset only 2 bytes\n\n    struct null_bytes* nb = (struct null_bytes*)bpf_lookup_elem(&amp;null_bytes_map, &amp;zero);\n    if(!nb){\n        return;\n    }\n    // write null_bytes into payload\n    bpf_probe_read_kernel(c-&gt;payload, 512, nb-&gt;data);\n}\n</code></pre> maps.c<pre><code>// -------&gt; sample tail-context\nstruct tail_context {\n    bool f1;\n    bool f2;\n    u8 payload[512];\n}\n\nstruct {\n     __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n     __type(key, u32);\n     __type(value, struct tail_context);\n     __uint(max_entries, 1);\n} tail_ctx_map SEC(\".maps\");\n// --------\n\n\n// data from below map is read only for resetting maps\nstruct null_bytes {\n  u8 data[8192]; // maximum null_bytes\n};\n\nstruct {\n  __uint(type, BPF_MAP_TYPE_ARRAY);\n  __type(key, u32);\n  __type(value, struct null_bytes);\n  __uint(max_entries, 1);\n  __uint(map_flags,\n         BPF_F_RDONLY_PROG | BPF_F_RDONLY); // makes the map read-only\n} null_bytes_map SEC(\".maps\");\n</code></pre>"},{"location":"blog/2025/10/29/ebpf-resetting-tail-contexts/#todo-experiment","title":"TODO Experiment","text":"<ul> <li>Use <code>bpf_loop</code> for zeroing the struct</li> </ul>"},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/","title":"eBPF: Tail calls (Part-2)","text":""},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/#objective","title":"Objective","text":"<ul> <li>to understand/learn passing data between tail-called functions</li> </ul> <p>Why ?</p> <p>There are use-cases where tail-called function must know processing performed in previous function.</p>"},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/#reasoning","title":"Reasoning","text":"<p>To share data among tail-called functions, we take advantage of the fact that, they are executed by same-cpu.</p> <p>Refer previous post to understand performing tail-calls.</p> <p>The additional things needed are:</p> <ul> <li>A <code>PERCPU_ARRAY</code> map</li> <li>A <code>tail_context</code> struct</li> </ul> <p>When initial function is triggered, </p> <ul> <li>Query the <code>PERCPU_ARRAY</code> map value at index 0 for <code>tail_context</code></li> <li>Reset the <code>tail_context</code> using <code>__builtin_memset</code></li> <li>Populate new values in <code>tail_context</code></li> </ul> <p>When subsequent tail-functions are triggered</p> <ul> <li>Query the <code>PERCPU_ARRAY</code> map value at index 0 for <code>tail_context</code></li> <li>Use/Populate values from <code>tail_context</code></li> </ul>"},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/#code","title":"Code","text":"programs.h<pre><code>#include \"maps.h\"\n\nu8 ZERO = 0;\n\n\nSEC(\"cgroup_skb/egress\")\nlong egress3(struct __sk_buff* ctx){\n    bpf_printk(\"[egress3] Someone called me\");\n\n    // Query tail_context\n    struct tail_context* ctx2 = (struct tail_context*)bpf_map_lookup_elem(&amp;tail_context_map, &amp;ZERO);\n    if(!ctx){\n        return SK_PASS;\n    }\n\n    // Use tail_context values\n    bpf_printk(\"[egress3] first=%d second=%d\", ctx2-&gt;value_from_1, ctx2-&gt;value_from_1);\n\n    return SK_PASS;\n}\n\nSEC(\"cgroup_skb/egress\")\nlong egress2(struct __sk_buff* ctx){\n\n\n    // Query tail context\n    struct tail_context* ctx2 = (struct tail_context*)bpf_map_lookup_elem(&amp;tail_context_map, &amp;ZERO);\n    if(!ctx){\n        return SK_PASS;\n    }\n\n    // Populate tail_context\n    ctx2-&gt;value_from_2 = 22;\n\n    bpf_printk(\"[egress2] Calling egress3\");\n    bpf_tail_call(ctx, &amp;tail_programs, TAIL_CALL_EGRESS_3)\n    return SK_PASS;\n}\n\n\n// Initial function\nSEC(\"cgroup_skb/egress\")\nlong egress1(struct __sk_buff* ctx){\n\n\n    // Query tail context\n    struct tail_context* ctx2 = (struct tail_context*)bpf_map_lookup_elem(&amp;tail_context_map, &amp;ZERO);\n    if(!ctx){\n        return SK_PASS;\n    }\n\n    // Reset tail context\n    __builtin_memset(ctx2, 0, sizeof(struct tail_context));\n\n    ctx2-&gt;value_from_1 = 11;\n\n    bpf_printk(\"[egress1] Calling egress2\");\n    bpf_tail_call(ctx, &amp;tail_programs, TAIL_CALL_EGRESS_2)\n    return SK_PASS;\n}\n</code></pre> maps.h<pre><code>// declare the index in array to use for tail-called function\n#define TAIL_CALL_EGRESS_2 0 \n#define TAIL_CALL_EGRESS_3 1 \n\n\n// declare the prototype of function to be stored\nlong egress2(struct __sk_buff* ctx);\nlong egress3(struct __sk_buff* ctx);\n\n\n// create map &amp; initialize values\nstruct {\n    __uint(type, BPF_MAP_TYPE_PROG_ARRAY);\n    __uint(max_entries, 1);\n    __type(key, __u32);\n    __array(values, long(struct __sk_buff* ctx));\n} tail_programs SEC(\".maps\") = {\n    .values = {\n        [TAIL_CALL_EGRESS_2] = (void *)&amp;egress2, \n        [TAIL_CALL_EGRESS_3] = (void *)&amp;egress3,\n\n\n    },\n};  \n\n// Custom tail_contxt\nstruct tail_context{\n    u8 value_from_1;\n    u8 value_from_2;\n}\n\n// Every CPU has its own private copy of this map\nstruct {\n    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n    __uint(max_entries, 1);\n    __type(key, __u32);\n    __type(value, struct tail_context);\n} tail_context_map SEC(\".maps\") \n</code></pre>"},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/#observations","title":"Observations","text":"<ul> <li><code>PERCPU_ARRAY</code> map has only 1 entry</li> <li>Reset on <code>tail_context</code> is performed only initially</li> </ul>"},{"location":"blog/2025/06/08/ebpf-tail-calls-part-2/#refer","title":"Refer","text":"<ul> <li>https://docs.ebpf.io/linux/map-type/BPF_MAP_TYPE_PERCPU_ARRAY/</li> <li>https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SKB/</li> <li>https://docs.ebpf.io/linux/concepts/tail-calls/</li> </ul>"},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/","title":"eBPF: Tail calls (Part-1)","text":""},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/#objective","title":"Objective","text":"<ul> <li>to understand performing tail-calls in eBPF</li> </ul>"},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/#reasoning","title":"Reasoning","text":"<p>In order to perform tail calls, we need to</p> <ul> <li>declare <code>prototype</code> of funcs to call</li> <li>declare map: <code>prog_array map</code> with key=u32, values=signature_of_funcs </li> <li>fill map:<ul> <li>can be done in userspace as well in kernelspace</li> </ul> </li> <li>use <code>bpf_tail_call</code> to redirect flow to func of interest</li> </ul>"},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/#code","title":"Code","text":"programs.h<pre><code>#include \"maps.h\" hl_lines=\"13 14\"\n\n// Called function\nSEC(\"cgroup_skb/egress\")\nlong egress2(struct __sk_buff* ctx){\n    bpf_printk(\"[egress2] Someone called me\");\n    return SK_PASS;\n}\n\n// Initial function\nSEC(\"cgroup_skb/egress\")\nlong egress1(struct __sk_buff* ctx){\n    bpf_printk(\"[egress1] Calling egress2\");\n    bpf_tail_call(ctx, &amp;tail_programs, TAIL_CALL_EGRESS_2)\n    return SK_PASS;\n}\n</code></pre> maps.h<pre><code>// declare the index in array to use for tail-called function\n#define TAIL_CALL_EGRESS_2 0 \n\n// declare the prototype of function to be stored\nlong egress2(struct __sk_buff* ctx);\n\n// create map &amp; initialize values\nstruct {\n    __uint(type, BPF_MAP_TYPE_PROG_ARRAY);\n    __uint(max_entries, 1);\n    __type(key, __u32);\n    __array(values, long(struct __sk_buff* ctx)); // signature of function\n} tail_programs SEC(\".maps\") = {\n    .values = {\n        [TAIL_CALL_EGRESS_2] = (void *)&amp;egress2, // filling values\n    },\n};  \n</code></pre>"},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/#observations","title":"Observations","text":"<ul> <li>same-cpu: callee function is executed by same-cpu</li> <li>same-context: caller and callee must have same ctx i.e program of same type</li> <li>no-new-stack: callee uses caller's stack</li> <li>no-return: callee doesn't returns to caller</li> </ul>"},{"location":"blog/2025/05/31/ebpf-tail-calls-part-1/#refer","title":"Refer","text":"<ul> <li> <p>https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SKB/</p> </li> <li> <p>https://docs.ebpf.io/linux/concepts/tail-calls/</p> </li> <li> <p>https://docs.ebpf.io/linux/helper-function/bpf_tail_call/</p> </li> <li> <p>https://github.com/cilium/tetragon/blob/c51dd078bfb568075ba1fb287f2447f29f709073/bpf/process/bpf_generic_rawtp.c#L27-L45</p> </li> </ul>"},{"location":"debug/ebpf/","title":"eBPF","text":""},{"location":"debug/ebpf/#for-grabbing-bpftool","title":"for grabbing bpftool","text":"<p>When <code>sudo apt install bpftool</code> doesn't work </p> <pre><code># For latest build follow below link\n# https://github.com/libbpf/bpftool/releases\n\nwget https://github.com/libbpf/bpftool/releases/download/v7.5.0/bpftool-v7.5.0-amd64.tar.gz\ntar xf bpftool*\nchmod +x ./bpftool\n./bpftool\n</code></pre>"},{"location":"debug/ebpf/#for-loading-program","title":"for loading program","text":"<pre><code>sudo mount -t bpf bpffs /sys/fs/bpf\nsudo bpftool prog load ./sample.o /sys/fs/bpf/sample\n</code></pre>"},{"location":"debug/ebpf/#for-reading-logs","title":"for reading logs","text":"<pre><code># with bpftool\nsudo bpftool prog tracelog\n\n# for k8s-debug pod\necho &gt; /host/sys/kernel/debug/tracing/trace\ncat /host/sys/kernel/debug/tracing/trace_pipe\n</code></pre> <ul> <li>https://unix.stackexchange.com/questions/747990/how-to-clear-the-sys-kernel-debug-tracing-trace-pipe-quickly</li> </ul>"},{"location":"debug/ebpf/#for-ebpf-lsm-kprobe-override-status","title":"for ebpf-lsm &amp; kprobe-override status","text":"<pre><code># for ebpf-lsm\ncat /sys/kernel/security/lsm\n\n# for override\ncat /boot/config-`uname -r` | grep CONFIG_BPF_KPROBE_OVERRIDE\n</code></pre>"},{"location":"debug/ebpf/#for-observing-performance-of-hooksprograms","title":"for observing performance of hooks/programs","text":"<ul> <li>Netflix/bpftop</li> </ul>"},{"location":"debug/ebpf/#for-co-re-guide","title":"for CO-RE guide","text":"<ul> <li>https://nakryiko.com/tags/bpf/</li> </ul>"},{"location":"debug/ebpf/#for-checking-available-features","title":"for checking available features","text":"<pre><code>sudo bpftool feature\n</code></pre>"},{"location":"debug/kubernetes/","title":"Kubernetes","text":"<p>Official Doc</p> <p>https://kubernetes.io/docs/tasks/debug/debug-cluster/</p>"},{"location":"debug/kubernetes/#for-debugging-node-with-privileged-pod","title":"for debugging node with privileged pod","text":"<pre><code>nodeName=$(kubectl get node -o name)\nkubectl debug $nodeName -it --image=ubuntu --profile=sysadmin\n</code></pre> <ul> <li>https://kubernetes.io/docs/tasks/debug/debug-cluster/kubectl-node-debug/</li> </ul>"},{"location":"debug/kubernetes/#for-debugging-node-with-crictl","title":"for debugging node with crictl","text":"<ul> <li>https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/</li> </ul>"},{"location":"debug/kubernetes/#for-exploring-specs","title":"for exploring specs","text":"<ul> <li>https://kubespec.dev/</li> </ul>"},{"location":"notes/bots_and_webhooks/","title":"Bots and Webhooks","text":""},{"location":"notes/bots_and_webhooks/#telegram-bot","title":"telegram-bot","text":"<ul> <li>to send messages on telegram channel using telegram-api, with bot-account</li> </ul>"},{"location":"notes/bots_and_webhooks/#flow","title":"flow","text":"<ul> <li> <p>create bot using <code>bot_father</code>, and save the access_token</p> <ul> <li>edit bot's permission to give it ability to interact with <code>channels</code></li> </ul> </li> <li> <p>create a new private-channel</p> </li> <li> <p>add new_bot as <code>admin</code> in new_channel </p> <ul> <li>try adding using mobile-phone, if unable to do from web</li> </ul> </li> <li> <p>remove <code>excess permissions</code>, keep only related to <code>post_message</code> </p> </li> <li> <p>send message to channel using bot-api by providing <code>channel_id</code> in query param or as json_payload</p> </li> </ul> <p>always prefix channel_id with <code>-100</code></p>"},{"location":"notes/bots_and_webhooks/#sample","title":"sample","text":"<pre><code>$tele_base=\"https://api.telegram.org/bot&lt;YOUR_BOT_TOKEN&gt;\"\n\ncurl -s -XPOST \"$tele_base/sendMessage\" \\\n     -H \"content-type:application/json\" \\\n     -d '{\"chat_id\":\"-1003051237226\", \"text\":\"text to private channel\"}' | jq\n</code></pre>"},{"location":"notes/bots_and_webhooks/#refer","title":"refer","text":"<ul> <li>https://core.telegram.org/bots/tutorial</li> <li>https://core.telegram.org/bots/api#sendmessage</li> </ul>"},{"location":"notes/bots_and_webhooks/#discord-webhook","title":"discord-webhook","text":""},{"location":"notes/bots_and_webhooks/#flow_1","title":"flow","text":"<ul> <li>create new channel, and then click on edit-channel</li> <li>click on integration and then click webhooks</li> <li>click <code>new-webhook</code> and copy the url</li> </ul>"},{"location":"notes/bots_and_webhooks/#sample_1","title":"sample","text":"<p>Send webhook on a thread</p> <pre><code>hook_url=\"\"\ncurl -XPOST \"$hook_url?thread_id=\" -H \"content-type:application/json\" \\\n    -d \"{\\\"content\\\":\\\"test\\\"}\"\n</code></pre>"},{"location":"notes/bots_and_webhooks/#refer_1","title":"refer","text":"<ul> <li>https://discord.com/developers/docs/resources/webhook#execute-webhook</li> </ul>"},{"location":"notes/build-kernel/","title":"Build Kernel","text":"<p>On following build steps, a vmlinux binary of about 30MB will get built. It can be used with firecracker-vm by specifying in <code>kernel_image_path</code>.</p>"},{"location":"notes/build-kernel/#build-steps","title":"Build Steps","text":"<ul> <li>Checkout latest code in current directory or download from https://www.kernel.org/</li> </ul> <pre><code>git clone --depth 1 -b master \\\n  https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git .\n</code></pre> <ul> <li>Create <code>.config</code> file, use firecracker minimal config</li> </ul> <pre><code>wget -O .config \\\n    https://raw.githubusercontent.com/firecracker-microvm/firecracker/refs/heads/main/resources/guest_configs/microvm-kernel-ci-x86_64-6.1.config\n</code></pre> <ul> <li>Add <code>pcie</code> and <code>virtio</code> related flags in <code>.config</code>, without these kernel won't boot (required for attaching block-devices)</li> </ul> <pre><code>## PCIE flags\n\nCONFIG_BLK_MQ_PCI=y\nCONFIG_PCI=y\nCONFIG_PCI_MMCONFIG=y\nCONFIG_PCI_MSI=y\nCONFIG_PCIEPORTBUS=y\nCONFIG_VIRTIO_PCI=y\nCONFIG_PCI_HOST_COMMON=y\nCONFIG_PCI_HOST_GENERIC=y\n\n\n# VIRTIO flags\nCONFIG_VIRTIO_MEM=y\nCONFIG_STRICT_DEVMEM=y\n</code></pre> <ul> <li>Do oldconfig</li> </ul> <pre><code>make oldconfig\n</code></pre> <ul> <li>Perform build</li> </ul> <pre><code>make -j $(nproc --all)\n</code></pre>"},{"location":"notes/build-kernel/#refer","title":"Refer","text":"<ul> <li>https://docs.kernel.org/admin-guide/quickly-build-trimmed-linux.html</li> </ul>"},{"location":"notes/firecracker/","title":"Firecracker VMM","text":"<p>Experiments with firecracker-microvm/firecracker</p> <p>Follow most of the steps from <code>get-started</code> to spin-up a minimal VM</p>"},{"location":"notes/firecracker/#to-get-started-with-firecracker","title":"to get-started with firecracker","text":"<ul> <li>https://github.com/firecracker-microvm/firecracker/blob/main/docs/getting-started.md</li> </ul>"},{"location":"notes/firecracker/#to-undersand-tuntap","title":"to undersand tuntap","text":"<ul> <li>https://www.packetcoders.io/virtual-networking-devices-tun-tap-and-veth-pairs-explained/</li> </ul>"},{"location":"notes/firecracker/#to-understand-ip-route","title":"to understand <code>ip route</code>","text":"<p>this is used for configuring networking inside VM</p> <ul> <li>https://linuxvox.com/blog/linux-ip-route/</li> <li>https://man7.org/linux/man-pages/man8/ip-route.8.html</li> </ul>"},{"location":"notes/firecracker/#about-drives","title":"about <code>drives</code>","text":"<ul> <li> <p>for all drives, <code>a device-file under /dev</code> is created in inside VM</p> <ul> <li>only <code>rootfs drive</code> is mounted automatically at <code>/</code>, </li> <li>rest of the drives are to be mounted manually<ul> <li>do <code>lsblk</code> to list all devices</li> </ul> </li> </ul> </li> <li> <p><code>path_on_host</code> can be either</p> <ul> <li><code>file-system image</code> created using <code>mkfs</code>,</li> <li><code>loop-device</code>, or any device. [checkout]</li> </ul> </li> </ul>"},{"location":"notes/firecracker/#run-script","title":"run script","text":"run.sh<pre><code>#!/bin/bash\n\nset -x\n\ndownload-kernel() {\n    ARCH=\"$(uname -m)\"\n    release_url=\"https://github.com/firecracker-microvm/firecracker/releases\"\n    latest_version=$(basename $(curl -fsSLI -o /dev/null -w %{url_effective} ${release_url}/latest))\n    CI_VERSION=${latest_version%.*}\n    latest_kernel_key=$(curl \"http://spec.ccfc.min.s3.amazonaws.com/?prefix=firecracker-ci/$CI_VERSION/$ARCH/vmlinux-&amp;list-type=2\" |\n        grep -oP \"(?&lt;=&lt;Key&gt;)(firecracker-ci/$CI_VERSION/$ARCH/vmlinux-[0-9]+\\.[0-9]+\\.[0-9]{1,3})(?=&lt;/Key&gt;)\" |\n        sort -V | tail -1)\n\n    # Download a linux kernel binary\n    wget \"https://s3.amazonaws.com/spec.ccfc.min/${latest_kernel_key}\"\n\n    latest_ubuntu_key=$(curl \"http://spec.ccfc.min.s3.amazonaws.com/?prefix=firecracker-ci/$CI_VERSION/$ARCH/ubuntu-&amp;list-type=2\" |\n        grep -oP \"(?&lt;=&lt;Key&gt;)(firecracker-ci/$CI_VERSION/$ARCH/ubuntu-[0-9]+\\.[0-9]+\\.squashfs)(?=&lt;/Key&gt;)\" |\n        sort -V | tail -1)\n    ubuntu_version=$(basename $latest_ubuntu_key .squashfs | grep -oE '[0-9]+\\.[0-9]+')\n\n    # Download a rootfs from Firecracker CI\n    wget -O ubuntu-$ubuntu_version.squashfs.upstream \"https://s3.amazonaws.com/spec.ccfc.min/$latest_ubuntu_key\"\n}\n\nspin-vm() {\n    sudo release-v1.13.1-x86_64/firecracker-v1.13.1-x86_64 --api-sock /tmp/firecracker.socket --config-file vm_template.json\n}\n\nsetup-overlay() {\n\n    local lower=\"./squashfs-root\"\n    local upper=\"./overlay-upper\"\n    local mount_point=\"./exp-overlay\"\n\n    sudo mount overlay -t overlay -olowerdir=$lower,upperdir=$upper,workdir=./work $mount_point\n\n}\n\n# run cmd\n$1\n</code></pre>"},{"location":"notes/firecracker/#vm-template","title":"vm template","text":"<p>below template is used with <code>spin-vm</code> command in <code>run-script</code></p> vm_template.json<pre><code>{\n    \"boot-source\": {\n        \"kernel_image_path\": \"vmlinux-6.1.141\",\n        \"boot_args\": \"console=ttyS0 reboot=k panic=1\",\n        \"initrd_path\": null\n    },\n    \"drives\": [\n        {\n            \"drive_id\": \"rootfs\",\n            \"partuuid\": null,\n            \"is_root_device\": true,\n            \"cache_type\": \"Unsafe\",\n            \"is_read_only\": false,\n            \"path_on_host\": \"ubuntu-24.04.ext4\",\n            \"io_engine\": \"Sync\",\n            \"rate_limiter\": null,\n            \"socket\": null\n        },\n        {\n            \"drive_id\": \"loop5_dev\",\n            \"partuuid\": null,\n            \"is_root_device\": false,\n            \"cache_type\": \"Unsafe\",\n            \"is_read_only\": false,\n            \"path_on_host\": \"/tmp/exp1.img\",\n            \"io_engine\": \"Sync\",\n            \"rate_limiter\": null,\n            \"socket\": null\n        }\n    ],\n    \"machine-config\": {\n        \"vcpu_count\": 2,\n        \"mem_size_mib\": 1024,\n        \"smt\": false,\n        \"track_dirty_pages\": false\n    },\n    \"balloon\": null,\n    \"network-interfaces\": [\n        {\n            \"iface_id\": \"1\",\n            \"host_dev_name\": \"tap0\",\n            \"guest_mac\": \"06:00:c0:a8:00:02\",\n            \"rx_rate_limiter\": null,\n            \"tx_rate_limiter\": null\n        }\n    ],\n    \"vsock\": null,\n    \"logger\": null,\n    \"metrics\": null,\n    \"mmds-config\": {\n        \"network_interfaces\": [\n            \"1\"\n        ],\n        \"ipv4_address\": \"169.254.169.250\",\n        \"version\": \"V2\",\n        \"imds_compat\": true\n    },\n    \"entropy\": null\n}\n</code></pre>"},{"location":"notes/loop-device/","title":"Loop device","text":""},{"location":"notes/loop-device/#steps","title":"Steps","text":"snippet.sh<pre><code># create backing file\ndd if=/dev/zero of=exp1.img bs=1MB count=16\n\n# convert file to ext4-fs\nmkfs.ext4 exp1.img\n\n# create loop device\nsudo losetup --find --show exp1.img\n\n# create folder to mount loop-device\nmkdir exp-fs\n\n# mount loop-device on exp-fs\nsudo mount /dev/loop&lt;NUM&gt; exp-fs\n\n# list files\nls exp-fs\n</code></pre>"},{"location":"notes/loop-device/#refer","title":"Refer","text":"<ul> <li>https://www.man7.org/linux/man-pages/man4/loop.4.html</li> </ul>"},{"location":"notes/qemu/","title":"Qemu","text":""},{"location":"notes/qemu/#micro-vm","title":"micro-vm","text":"<p>to start firecracker like micro-vm</p> <ul> <li>https://www.qemu.org/docs/master/system/i386/microvm.html</li> </ul> run.sh<pre><code>#!/bin/bash\n\nstart-vm() {\n    qemu-system-x86_64 \\\n        -M microvm,x-option-roms=off,pit=off,pic=off,isa-serial=off,rtc=off \\\n        -enable-kvm -cpu host -m 512m -smp 2 \\\n        -kernel &lt;path_to_vmlinux&gt; -append \"console=hvc0 root=/dev/vda\" \\\n        -nodefaults -no-user-config -nographic \\\n        -chardev stdio,id=virtiocon0 \\\n        -device virtio-serial-device \\\n        -device virtconsole,chardev=virtiocon0 \\\n        -drive id=test,file=ubuntu-24.04.ext4,format=raw,if=none \\\n        -device virtio-blk-device,drive=test \\\n        -netdev tap,id=tap0,script=no,downscript=no \\\n        -device virtio-net-device,netdev=tap0\n}\n</code></pre>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/ebpf/","title":"ebpf","text":""},{"location":"blog/page/2/","title":"Logs","text":""},{"location":"blog/archive/2025/page/2/","title":"2025","text":""},{"location":"blog/category/ebpf/page/2/","title":"ebpf","text":""}]}